#### 基础架构

#### 数据库设计规范

##### 字段

1. 优先选择符合存储需要的最小的数据类型

   - 原因：列的字段越大，建立索引时所需要的空间也就越大，这样一页中所能存储的索引节点的数量也就越少也越少，在遍历时所需要的 IO 次数也就越多，索引的性能也就越差。

   - 方法1：将字符串转换成数字类型存储,如:将 IP 地址转换成整形数据；MySQL 提供了两个方法来处理 ip 地址；1.inet_aton 把 ip 转为无符号整型 (4-8 位)；2.inet_ntoa 把整型的 ip 转为地址；插入数据前，先用 inet_aton 把 ip 地址转为整型，可以节省空间，显示数据时，使用 inet_ntoa 把整型的 ip 地址转为地址显示即可

   - 方法2：对于非负型的数据 (如自增 ID,整型 IP) 来说,要优先使用无符号整型来存储

   - 原因：无符号相对于有符号可以多出一倍的存储空间

     SIGNED INT -2147483648~2147483647     UNSIGNED INT 0~4294967295
     VARCHAR(N) 中的 N 代表的是字符数，而不是字节数，使用 UTF8 存储 255 个汉字 Varchar(255)=765 个字节。过大的长度会消耗更多的内存。

2. 避免使用 TEXT,BLOB 数据类型，最常见的 TEXT 类型可以存储 64k 的数据

   - 建议把 BLOB 或是 TEXT 列分离到单独的扩展表中

     MySQL 内存临时表不支持 TEXT、BLOB 这样的大数据类型，如果查询中包含这样的数据，在排序等操作时，就不能使用内存临时表，必须使用磁盘临时表进行。而且对于这种数据，MySQL 还是要进行二次查询，会使 sql 性能变得很差，但是不是说一定不能使用这样的数据类型；

     如果一定要使用，建议把 BLOB 或是 TEXT 列分离到单独的扩展表中，查询时一定不要使用 select * 而只需要取出必要的列，不需要 TEXT 列的数据时不要对该列进行查询。

   - TEXT 或 BLOB 类型只能使用前缀索引

     因为MySQL[1] 对索引字段长度是有限制的，所以 TEXT 类型只能使用前缀索引，并且 TEXT 列上是不能有默认值的

3. 避免使用 ENUM 类型

   - 修改 ENUM 值需要使用 ALTER 语句
   - ENUM 类型的 ORDER BY 操作效率低，需要额外操作
   - 禁止使用数值作为 ENUM 的枚举值

4. 尽可能把所有列定义为 NOT NULL

   - 原因：

     索引 NULL 列需要额外的空间来保存，所以要占用更多的空间

     进行比较和计算时要对 NULL 值做特别的处理

5. 使用 TIMESTAMP(4 个字节) 或 DATETIME 类型 (8 个字节) 存储时间

   - TIMESTAMP 存储的时间范围 1970-01-01 00:00:01 ~ 2038-01-19-03:14:07
   - TIMESTAMP 占用 4 字节和 INT 相同，但比 INT 可读性高
   - 超出 TIMESTAMP 取值范围的使用 DATETIME 类型存储
   - 经常会有人用字符串存储日期型的数据（不正确的做法）
     - 缺点 1：无法用日期函数进行计算和比较
     - 缺点 2：用字符串存储日期要占用更多的空间

6. 同财务相关的金额类数据必须使用 decimal 类型

   - 非精准浮点：float,double
   - 精准浮点：decimal
   - Decimal 类型为精准浮点数，在计算时不会丢失精度
   - 占用空间由定义的宽度决定，每 4 个字节可以存储 9 位数字，并且小数点要占用一个字节
   - 可用于存储比 bigint 更大的整型数据

##### 索引

1. 限制每张表上的索引数量,建议单张表索引不超过 5 个

2. 禁止给表中的每一列都建立单独的索引

3. 每个 Innodb 表必须有个主键

   - Innodb 是一种索引组织表：数据的存储的逻辑顺序和索引的顺序是相同的。每个表都可以有多个索引，但是表的存储顺序只能有一种。
   - Innodb 是按照主键索引的顺序来组织表的
   - 不要使用更新频繁的列作为主键，不适用多列主键（相当于联合索引）
   - 不要使用 UUID,MD5,HASH,字符串列作为主键（无法保证数据的顺序增长）
   - 主键建议使用自增 ID 值

4. 常见索引列建议

   - 出现在 SELECT、UPDATE、DELETE 语句的 WHERE 从句中的列

   - 包含在 ORDER BY、GROUP BY、DISTINCT 中的字段
   - 并不要将符合 1 和 2 中的字段的列都建立一个索引， 通常将 1、2 中的字段建立联合索引效果更好
   - 多表 join 的关联列

5. 如何选择索引列的顺序

   - 建立索引的目的：希望通过索引进行数据查找，减少随机 IO，增加查询性能 ，索引能过滤出越少的数据，则从磁盘中读入的数据也就越少
   - 区分度最高的放在联合索引的最左侧（区分度=列中不同值的数量/列的总行数）
   - 尽量把字段长度小的列放在联合索引的最左侧（因为字段长度越小，一页能存储的数据量越大，IO 性能也就越好）
   - 使用最频繁的列放到联合索引的左侧（这样可以比较少的建立一些索引）

6. 避免建立冗余索引和重复索引（增加了查询优化器生成执行计划的时间）

7. 索引 SET 规范

   - 尽量避免使用外键约束
   - 不建议使用外键约束（foreign key），但一定要在表与表之间的关联键上建立索引
   - 外键可用于保证数据的参照完整性，但建议在业务端实现
   - 外键会影响父表和子表的写操作从而降低性能

8. 对于频繁的查询优先考虑使用覆盖索引

   - 覆盖索引：就是包含了所有查询字段 (where,select,ordery by,group by 包含的字段) 的索引

   - 优点：

   - 避免 Innodb 表进行索引的二次查询: Innodb 是以聚集索引的顺序来存储的，对于 Innodb 来说，二级索引在叶子节点中所保存的是行的主键信息，如果是用二级索引查询数据的话，在查找到相应的键值后，还要通过主键进行二次查询才能获取我们真实所需要的数据。而在覆盖索引中，二级索引的键值中可以获取所有的数据，避免了对主键的二次查询 ，减少了 IO 操作，提升了查询效率。
   - 可以把随机 IO 变成顺序 IO 加快查询效率: 由于覆盖索引是按键值的顺序存储的，对于 IO 密集型的范围查找来说，对比随机从磁盘读取每一行的数据 IO 要少的多，因此利用覆盖索引在访问时也可以把磁盘的随机读取的 IO 转变成索引查找的顺序 IO。

##### SQL

1. 建议使用预编译语句进行数据库操作

2. 避免数据类型的隐式转换

3. 充分利用表上已经存在的索引

4. 数据库设计时，应该要对以后扩展进行考虑

5. 序连接不同的数据库使用不同的账号，进制跨库查询

6. 禁止使用 SELECT * 必须使用 SELECT <字段列表> 查询

7. 禁止使用不含字段列表的 INSERT 语句

8. 避免使用子查询，可以把子查询优化为 join 操作

9. 避免使用 JOIN 关联太多的表

10. 减少同数据库的交互次数

11. 对应同一列进行 or 判断时，使用 in 代替 or

12. 禁止使用 order by rand() 进行随机排序

13. WHERE 从句中禁止对列进行函数转换和计算

14. 在明显不会有重复值时使用 UNION ALL 而不是 UNION

15. 拆分复杂的大 SQL 为多个小 SQL

16. 如果知道查询结果只有一条或者只要最大/最小一条记录，建议用limit 1

17. 优化limit分页

18. 应尽量避免在 where 子句中对字段进行表达式操作，这将导致系统放弃使用索引而进行全表扫

19. Inner join 、left join、right join，优先使用Inner join，如果是left join，左边表结果尽量小

20. 如果插入数据过多，考虑批量插入

21. 在适当的时候，使用覆盖索引

22. where子句中考虑使用默认值代替null

23. 为了提高group by 语句的效率，可以在执行到该语句前，把不需要的记录过滤掉

24. 如果字段类型是字符串，where时一定用引号括起来，否则索引失效

    **具体参考MySQL.xmind文档**

##### 表

1. 临时库表必须以 tmp_为前缀并以日期为后缀，备份表必须以 bak_为前缀并以日期 (时间戳) 为后缀
2. 尽量控制单表数据量的大小,建议控制在 500 万以内
   - 500 万并不是 MySQL 数据库的限制，过大会造成修改表结构，备份，恢复都会有很大的问题。
   - 可以用历史数据归档（应用于日志数据），分库分表（应用于业务数据）等手段来控制数据量大小

##### 库

1. 超 100 万行的批量写 (UPDATE,DELETE,INSERT) 操作,要分批多次进行操作

   - 大批量操作可能会造成严重的主从延迟

     主从环境中,大批量操作可能会造成严重的主从延迟，大批量的写操作一般都需要执行一定长的时间， 而只有当主库上执行完成后，才会在其他从库上执行，所以会造成主库与从库长时间的延迟情况

   - binlog 日志为 row 格式时会产生大量的日志

   - 大批量写操作会产生大量日志，特别是对于 row 格式二进制数据而言，由于在 row 格式中会记录每一行数据的修改，我们一次修改的数据越多，产生的日志量也就会越多，日志的传输和恢复所需要的时间也就越长，这也是造成主从延迟的一个原因

   - 避免产生大事务操作

   - 大批量修改数据，一定是在一个事务中进行的，这就会造成表中大批量数据进行锁定，从而导致大量的阻塞，阻塞会对 MySQL 的性能产生非常大的影响。

     特别是长时间的阻塞会占满所有数据库的可用连接，这会使生产环境中的其他应用无法连接到数据库，因此一定要注意大批量写操作要进行分批

2. 对于大表使用 pt-online-schema-change 修改表结构

   - 避免大表修改产生的主从延迟
   - 避免在对表字段进行修改时进行锁表
   - 对大表数据结构的修改一定要谨慎，会造成严重的锁表操作，尤其是生产环境，是不能容忍的
   - pt-online-schema-change 它会首先建立一个与原表结构相同的新表，并且在新表上进行表结构的修改，然后再把原表中的数据复制到新表中，并在原表中增加一些触发器。把原表中新增的数据也复制到新表中，在行所有数据复制完成之后，把新表命名成原表，并把原来的表删除掉。把原来一个 DDL 操作，分解成多个小的批次进行。

3. 禁止为程序使用的账号赋予 super 权限

   - 当达到最大连接数限制时，还运行 1 个有 super 权限的用户连接
     super 权限只能留给 DBA 处理问题的账号使用

4. 对于程序连接数据库账号,遵循权限最小原则

   - 程序使用数据库账号只能在一个 DB 下使用，不准跨库
   - 程序使用的账号原则上不准有 drop 权限

#### 单表优化

- 分析：不要上来就考虑分库分表，这样会带来逻辑、运维、部署的各种问题；一般来说，以整型值为主的表在千万级以下，字符串为主的表在五百万以下是没有问题的；同时MySQL单表的性能仍然可以进行优化，甚至能正常支撑千万级以上的数据量

##### 字段

1. 尽量使用TINYINT、SMALLINT、MEDIUM_INT作为整数类型而非INT，如果非负则加上UNSIGNED
2. VARCHAR的长度只分配真正需要的空间
3. 使用枚举或整数代替字符串类型
4. 尽量使用TIMESTAMP而非DATETIME
5. 单表不要有太多字段，建议在20以内
6. 避免使用NULL字段，很难查询优化且占用额外索引空间
7. 用整型来存IP
8. 索引并不是越多越好，要根据查询有针对性的创建，考虑在WHERE和ORDER BY命令上涉及的列建立索引，可根据EXPLAIN来查看是否用了索引还是全表扫描
9. 应尽量避免在WHERE子句中对字段进行NULL值判断，否则将导致引擎放弃使用索引而进行全表扫描
10. 值分布很稀少的字段不适合建索引，例如"性别"这种只有两三个值的字段
11. 字符字段只建前缀索引
12. 字符字段最好不要做主键
13. 不用外键，由程序保证约束
14. 尽量不用UNIQUE，由程序保证约束
15. 使用多列索引时主意顺序和查询条件保持一致，同时删除不必要的单列索引

##### 查询SQL

1. 可通过开启慢查询日志来找出较慢的SQL
2. 不做列运算：SELECT id WHERE age + 1 = 10，任何对列的操作都将导致表扫描，它包括数据库教程函数、计算表达式等等，查询时要尽可能将操作移至等号右边
3. sql语句尽可能简单：一条sql只能在一个cpu运算；大语句拆小语句，减少锁时间；一条大sql可以堵死整个库
4. 不用SELECT *
5. OR改写成IN：OR的效率是n级别，IN的效率是log(n)级别，in的个数建议控制在200以内
6. 不用函数和触发器，在应用程序实现
7. 避免%xxx式查询
8. 少用JOIN
9. 使用同类型进行比较，比如用'123'和'123'比，123和123比
10. 尽量避免在WHERE子句中使用!=或<>操作符，否则将引擎放弃使用索引而进行全表扫描
11. 对于连续数值，使用BETWEEN不用IN：SELECT id FROM t WHERE num BETWEEN 1 AND 5
12. 列表数据不要拿全表，要使用LIMIT来分页，每页数量也不要太大

##### 引擎

###### MyISAM

- 不支持行锁，读取时对需要读到的所有表加锁，写入时则对表加排它锁
- 不支持事务
- 不支持外键
- 不支持崩溃后的安全恢复
- 在表有读取查询的时候，支持往表中插入新纪录
- 支持BLOB和TEXT的前500个字符索引，支持全文索引
- 支持延迟更新索引，极大提升写入性能
- 对于不会进行修改的表，支持压缩表，极大减少磁盘空间占用

InnoDB

- 支持行锁，采用MVCC来支持高并发
- 支持事务
- 支持外键
- 支持崩溃后的安全恢复

总结：MyISAM适合SELECT密集型的表，而InnoDB适合INSERT和UPDATE密集型的表

#### 分库分表

##### 1、为什么要进行分库分表？

- 考察点1：为什么要分库分表（设计高并发系统的时候，数据库层面如何设计？）

- 考察点2：用过哪些分库分表中间件？他们的优势和劣势是什么？

- 考察点3：具体如何对数据库进行垂直拆分或水平拆分的？

​		分库分表一定是为了支撑高并发、数据量大两个问题。具体来说，可能分表不分库，也可能分库不分表。

- **分表**：单表数据量过大，会极大影响你的sql执行性能（一般单表几百万数据）

- **分库**：一个库最多支撑并发2000,，就需要扩容了，一个健康的单库并发最好保持在每秒1000左右

​        **常见分库分表中间件：Sharding-jdbc、Mycat**

​		sharding-jdbc：当当开源，Client层方案，支持分库分表、读写分离、分布式id生成、柔性事务（最大努力送达型事务、TCC事务）。优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能相对较高；缺点是升级时需要各个系统都重新升级版本再发布，各个系统都耦合了sharding-jdbc的依赖。

​		Mycat：基于Cobar改造，proxy层方案，功能完善。优点是各个项目之间是透明的，不需要管Mycat的升级版本等问题；缺点是需要部署，自己运维一套中间件，成本高。

​		水平拆分：将单表的数据分担到多个库的多个表里，表的结构都一样，所有表的数据加起来才是全部数据。（作用就是用多个库来扛更高的并发，以及用多个库的存储容量来进行扩容）

​		![database-split-horizon](https://doocs.github.io/advanced-java/docs/high-concurrency/images/database-split-horizon.png)

​		垂直拆分：将单表的很多字段进行拆分成多个表，或者是多个库，每个表的结构不同（几张不同的关联表）；一般会将较少访问频率高的字段放入一个表，将较多的访问频率较少的字段放入另外一个表

![database-split-vertically](https://doocs.github.io/advanced-java/docs/high-concurrency/images/database-split-vertically.png)

​		上述中间件都支持分库分表，中间件可以根据你指定的某个字段值，比如说userid，自动路由到对应的库，然后再自动路由到对应的表里去。

​		分库分表的方式：

1. range：每个库一段连续的数据，比如时间范围。优点是：扩容简单，如每个月一个库；缺点是这种方法容易产生热点问题，即流量都打在最新数据上。
2. hash：按照某字段hash一下均匀分散，较为常用；优点是每个库的数据量和请求压力平均分布，缺点是扩容麻烦，在数据迁移时，之前的数据需要重新计算hash值并重新分配到不同的库或表

##### 2、分库分表如何平滑过渡？

- 考察点：即如何设计才能让系统从单库单表**动态切换**到分库分表上？

######          分库分表的常见步骤

- 选择一个数据库中间件，调研、学习、测试；
- 设计你的分库分表的一个方案，你要分成多少个库，每个库分成多少个表，比如 3 个库，每个库 4 个表；
- 基于选择好的数据库中间件，以及在测试环境建立好的分库分表的环境，然后测试一下能否正常进行分库分表的读写；
- 完成单库单表到分库分表的**迁移**，双写方案；
- 线上系统开始基于分库分表对外提供服务；

######         停机迁移方案

​		挂公告：0点~6点运维，无法访问；0点时，系统停掉，提前写好**导数的一次性工具**，此时跑起来，将单库单表的数据读出来并写入分库分表里；导数完毕后，修改数据库连接配置、代码、SQL等。（比较low的方案）

![database-shard-method-1](https://doocs.github.io/advanced-java/docs/high-concurrency/images/database-shard-method-1.png)

###### 		双写迁移方案

​		在线上系统，之前所有写库的地方，增删改操作，除了对老库增删改，都加上对新库的增删改，这就是所谓的**双写**，即同时写老库和新库。

​		系统部署后，新库数据肯定差很多，用上文说的导数工具，跑起来读老库数据写新库，写的时候根据gmt_modified这类字段判断这条数据最后修改的时间，除非是读出来的数据在新库里没有，或者是比新库的数据新才会写（即不允许老数据覆盖新数据）

​		导完一轮后，有可能数据还是不一致，需要程序自动做一轮校验，若有不一样的，从老库读数据再次写，反复循环，直到两个库所有表的数据一致为止。

![database-shard-method-2](https://doocs.github.io/advanced-java/docs/high-concurrency/images/database-shard-method-2.png)

##### 3、如何设计可以动态的扩容方案？

- 考察点：在分库分表完成后，已经建立好的库和表支撑不住了，如何进行扩容？

######         停机扩容（不推荐）

​		步骤类似停机迁移，唯一不同是导数工具需要把现有库表的数据抽取慢慢倒入新的库表，但不推荐，一般来说，分库分表就是因为数据量过大；在单库单表到分库分表的时候，数据量可能不是很大，单表可能就两三千万，可以写个工具，多弄几台机器并行跑，1小时可能就完事了；倘若3个库+12张表，数据量达到亿级别，导数据就得几个小时，后续还得修改配置，重启系统，测试验证...

###### 		优化方案

​		可以一开始就32库+32表，即1024张表（无论并发支撑或数据量支撑都没问题），利用模32的方法进行路由

​		假设每个库正常承载写入并发量1000,32个库就是3.2w，如果每个库承载1.5k的写并发，即可以达到1.5*32=4.8w的写并发，再加一个MQ，削峰，每秒写入MQ8w条，每秒消费5w条；

​		对于数据量，每个表放500万，那么可以放50亿条数据

​		开始可能这个库是逻辑库，即一个MySQL服务器建了n个库，比如32，后面拆分就是在库和MySQL服务器之间做迁移，系统改一下配置；这样最多可以扩展到32个MySQL服务器，每个数据库服务器是一个库；若还不够，最多可以扩展到1024个服务器，每个数据库一张表；若需要减少库的数量，只要按倍数缩容就行了，修改一下路由规则

​		步骤：

1. 设定好几台数据库服务器，每台服务器上几个库，每个库多少个表，推荐是 32 库 * 32 表，对于大部分公司来说，可能几年都够了
2. 路由的规则，orderId 模 32 = 库，orderId / 32 模 32 = 表
3. 扩容的时候，申请增加更多的数据库服务器，装好 MySQL，呈倍数扩容，4 台服务器，扩到 8 台服务器，再到 16 台服务器
4. 由 DBA 负责将原先数据库服务器的库，迁移到新的数据库服务器上去，库迁移是有一些便捷的工具的
5. 我们这边就是修改一下配置，调整迁移的库所在数据库服务器的地址
6. 重新发布系统，上线，原先的路由规则变都不用变，直接可以基于 n 倍的数据库服务器的资源，继续进行线上系统的提供服务

##### 4、分库分表之后，id主键如何处理？（分布式id）

- 考察点：分成多个表之后，每个表的id都是从1开始累加，这时需要一个全局唯一的id来支持

######         数据库自增id

​		系统每次得到一个id，往一个库的一个表里插入一条无含义的业务数据，然后获取数据库自增的这个id，拿到这个id后再到分库分表里进行写入。

​		好处是方便简单，缺点是**单库生成**自增id，高并发场景下不适用；改进：开一个服务，这个服务拿到当前最大id值，自己递增几个id，一次性返回一批id，然后再把最大id修改成递增几个id最大的一个值，但都是基于单库

​		适合场景：若是由于**并发不高、数据量过大**导致的分库分表扩容，可以采用这个方案

###### 		设置数据库sequence或者表自增字段步长

​		可以通过设置数据库 sequence 或者表的自增字段步长来进行水平伸缩。

​		比如说，现在有 8 个服务节点，每个服务节点使用一个 sequence 功能来产生 ID，每个 sequence 的起始 ID 不同，并且依次递增，步长都是 8。

![database-id-sequence-step](https://doocs.github.io/advanced-java/docs/high-concurrency/images/database-id-sequence-step.png)

​		适合场景：在用户防止产生id重复时，可以使用；但服务节点固定、步长固定，若需要增加节点，就不好操作了

###### 		UUID

​		`UUID.randomUUID().toString().replace("-", "") -> sfsdf23423rr234sfdaf`

​		上述两种方式都是基于数据库，这种就是本地生成；缺点是UUID过长，占用空间大，且**作为主键性能太差**；更重要的是，UUID不具有有序性，会导致 B+ 树索引在写的时候有过多的随机写操作（连续的 ID 可以产生部分顺序写），还有，由于在写的时候不能产生有顺序的 append 操作，而需要进行 insert 操作，将会读取整个 B+ 树节点到内存，在插入这条记录后会将整个节点写回磁盘，这种操作在记录占用空间比较大的情况下，性能下降明显。

​		适合场景：随机生成文件名、编号等，主键不能用UUID

###### 		获取系统当前时间

​		在高并发条件下，比如一秒并发几千，会有重复情况，不用考虑

​		适合场景：可以将当前时间+业务字段组合作为id

###### 		snowflake算法

​		twitter开源的分布式id生成算法，采用Scala语言实现，是把一个 64 位的 long 型的 id，1 个 bit 是不用的，用其中的 41 bits 作为毫秒数，用 10 bits 作为工作机器 id，12 bits 作为序列号

​		**工具类可参考**https://doocs.github.io/advanced-java/#/./docs/high-concurrency/database-shard-global-id-generate

```
0 | 0001100 10100010 10111110 10001001 01011100 00 | 10001 | 1 1001 | 0000 00000000
```

- 1 bit：不用，为啥呢？因为二进制里第一个 bit 为如果是 1，那么都是负数，但是我们生成的 id 都是正数，所以第一个 bit 统一都是 0。
- 41 bits：表示的是时间戳，单位是毫秒。41 bits 可以表示的数字多达 `2^41 - 1` ，也就是可以标识 `2^41 - 1` 个毫秒值，换算成年就是表示69年的时间。
- 10 bits：记录工作机器 id，代表的是这个服务最多可以部署在 2^10 台机器上，也就是 1024 台机器。但是 10 bits 里 5 个 bits 代表机房 id，5 个 bits 代表机器 id。意思就是最多代表 `2^5` 个机房（32 个机房），每个机房里可以代表 `2^5` 个机器（32台机器）。
- 12 bits：这个是用来记录同一个毫秒内产生的不同 id，12 bits 可以代表的最大正整数是 `2^12 - 1 = 4096` ，也就是说可以用这个 12 bits 代表的数字来区分**同一个毫秒内**的 4096 个不同的 id。、

#### 读写分离

##### 1、如何实现MySQL的读写分离？

- 考察点：高并发肯定需要做读写分离，而且大部分场景都是读多写少，即写一个主库，挂多个从库，从多个从库来读，那么如何实现MySQL的读写分离？MySQL主从复制的原理是什么？如何解决MySQL主从同步的延时问题？

######         如何实现MySQL的读写分离？

​		即基于主从复制架构，即一个主库，挂多个从库，主库用来写，然后主库会将数据同步到从库

###### 		MySQL主从复制原理是什么？

​		主库将变更写入binlog日志，然后从库连接到主库之后，从库有一个IO线程，将主库的binlog日志拷贝到自己本地，写入一个relay中继日志中，接着从库中有一个SQL线程会从中继日志中读取binlog，然后执行binlog日志中的内容，也就是在自己本地再次执行一遍SQL，这样即可以保证自己跟主库的数据是一样的

![mysql-master-slave](https://doocs.github.io/advanced-java/docs/high-concurrency/images/mysql-master-slave.png)

###### 		主从同步延时问题

​		主库上写入binlog日志是并行的，但从库上同步数据是串行化的，在高并发场景下，从库的数据一定会比主库慢一些，**有延时性**，可能经常刚写入主库的数据读不到，要等几十毫秒等才能读到

###### 		从库数据丢失问题

​		如果主库突然宕机，数据还没同步到从库，有些数据在从库上就丢失了

###### 		半同步复制

​		解决从库数据丢失问题。半同步复制也叫semi-sync复制，指的是主库写入binlog日志后，就会**强制**立即将数据同步到从库，从库将日志写入自己本地的relay log后，会返回一个ack给主库，主库接收到至少一个从库的ack之后才会确认写操作已完成

###### 		并行复制

​		解决主从同步延时问题。指的是从库开启多个线程，并行读取relay log中不同库的日志，然后并行重放不同库的日志，这是库级别的并行。

​		一般来说，如果主从延迟较为严重，有以下解决方案：

- 分库，将一个主库拆分为多个主库，每个主库的写并发就减少了几倍，此时主从延迟可以忽略不计。
- 打开 MySQL 支持的并行复制，多个库并行复制。如果说某个库的写入并发就是特别高，单库写并发达到了 2000/s，并行复制还是没意义。
- 重写代码，写代码的同学，要慎重，插入数据时立马查询可能查不到。
- 如果确实是存在必须先插入，立马要求就查询到，然后立马就要反过来执行一些操作，对这个查询**设置直连主库**。**不推荐**这种方法，你要是这么搞，读写分离的意义就丧失了。

#### 面试题

##### 1、select a,b from table where c,d group by e,f   如何建立索引？

##### 2、MVCC

##### 3、四种隔离级别及解决的问题？

##### 4、表级锁与行级锁？

##### 5、对一个七表关联的MySQL出现慢查询如何处理？

##### 6、MySQL的聚簇索引、非聚簇索引？