# 基础

三大范式

# 基础架构

## 存储引擎

（1）MySQL存储引擎简介

​		MySQL默认的存储引擎时InnoDB，并且在5.7版本所有的存储引擎中只有InnoDB是事务型存储引擎。

​		查看MySQL当前默认的存储引擎：

```
mysql> show variables like '%storage_engine%';
```

​		查看表的存储引擎

```
show table status like "table_name" ;
```

（2）MyISAM和InnoDB区别

1. **是否⽀持⾏级锁** : MyISAM 只有表级锁(table-level locking)，⽽InnoDB ⽀持⾏级锁(rowlevel locking)和表级锁,默认为⾏级锁。
2. **是否⽀持事务和崩溃后的安全恢复**： MyISAM 强调的是性能，每次查询具有原⼦性,其执⾏速度 ⽐InnoDB类型更快，但是不提供事务⽀持。但是InnoDB 提供事务⽀持事务，外部键等⾼级数据 库功能。 具有事务(commit)、回滚(rollback)和崩溃修复能⼒(crash recovery capabilities)
3. **是否⽀持外键**： MyISAM不⽀持，⽽InnoDB⽀持。
4. **是否⽀持MVCC** ：仅 InnoDB ⽀持。应对⾼并发事务, MVCC⽐单纯的加锁更⾼效;**MVCC只在 READ COMMITTED 和 REPEATABLE READ 两个隔离级别下⼯作**;MVCC可以使⽤ 乐观 (optimistic)锁 和 悲观(pessimistic)锁来实现;各数据库中MVCC实现并不统⼀。

## 多版本并发控制

指的是一种提高并发的技术。早期的数据库系统，只有读读之间可以并发，读写、写读、写写都要阻塞。**引入多版本并发控制之后，只有写写相互阻塞，其余操作都可以并行操作**，这样大幅度提高了InnoDB的并发度。

在实现上，与Postgres在数据行上实现多版本不同，InnoDB是在undolog中实现的，通过undolog可以找回数据的历史版本。找回的数据历史版本可以提供给用户读（按照隔离级别的定义，有些读请求只能看到比较老的数据版本），也可以在回滚的时候覆盖数据页上的数据。在InnoDB内部中，**会记录一个全局的活跃读写事务数组，其主要用来判断事务的可见性。**

通常可以认为MVCC是行级锁的一个变种，但是它在很多情况下避免了加锁操作，因为开销更低。虽然实现机制有所不同，但大都实现了非阻塞的读操作，写操作也只锁定必要的行。MVCC的实现方式有多种，典型的有**乐观并发控制**和**悲观并发控制**。MVCC只在READ COMMITTED和REPEATABLE READ两个隔离级别下工作。其他两个隔离级别和MVCC不兼容，因为READ UNCOMMITTED总是读取最新的数据行，而不是符合当前事务版本的数据行。而SERIALIZABLE则会对所有读取的行都加锁。

MVCC是通过在每行记录后面保存三个字段来实现的。

- 6字节的**事务ID（DB_TRX_ID）**：用来标识最近一次对本行记录做修改(insert|update)的事务的标识符, 即最后一次修改(insert|update)本行记录的事务id。至于delete操作，在innodb看来也不过是一次update操作，更新行中的一个特殊位将行表示为deleted, **并非真正删除**。

- 7字节的`回滚指针`(`DB_ROLL_PTR`)字段: 指写入回滚段(rollback segment)的 `undo log` record (撤销日志记录记录)。
  如果一行记录被更新, 则 `undo log` record 包含 '重建该行记录被更新之前内容' 所必须的信息。

- 6字节的`DB_ROW_ID`字段: 包含一个随着新行插入而单调递增的行ID, 当由innodb自动产生聚集索引时，聚集索引会包括这个行ID的值，否则这个行ID不会出现在任何索引中。结合聚簇索引的相关知识点, 我的理解是, 如果我们的表中没有主键或合适的唯一索引, 也就是无法生成聚簇索引的时候, InnoDB会帮我们自动生成聚集索引, 但聚簇索引会使用DB_ROW_ID的值来作为主键; 如果我们有自己的主键或者合适的唯一索引, 那么聚簇索引中也就不会包含 DB_ROW_ID 了 。

  **MVCC的特点**

  - 每行数据都存在一个版本，每次数据更新时都更新该版本
  - 修改时Copy出当前版本, 然后随意修改，各个事务之间无干扰
  - 保存时比较版本号，如果成功(commit)，则覆盖原记录, 失败则放弃copy(rollback)
  - 就是每行都有版本号，保存时根据版本号决定是否成功，**听起来含有乐观锁的味道, 因为这看起来正是，在提交的时候才能知道到底能否提交成功**

  而InnoDB实现MVCC的方式是：

  - 事务以排他锁的形式修改原始数据
  - 把修改前的数据存放于undo log，通过回滚指针与主数据关联
  - 修改成功（commit）啥都不做，失败则恢复undo log中的数据（rollback）

  本质区别：当修改数据时是否要**排他锁定**，如果锁定了还算不算是MVCC？

  - Innodb的实现真算不上MVCC, 因为并没有实现核心的多版本共存, `undo log` 中的内容只是串行化的结果, 记录了多个事务的过程, 不属于多版本共存。但理想的MVCC是难以实现的, 当事务仅修改一行记录使用理想的MVCC模式是没有问题的, 可以通过比较版本号进行回滚, 但当事务影响到多行数据时, 理想的MVCC就无能为力了。
  - 比如, 如果事务A执行理想的MVCC, 修改Row1成功, 而修改Row2失败, 此时需要回滚Row1, 但因为Row1没有被锁定, 其数据可能又被事务B所修改, 如果此时回滚Row1的内容，则会破坏事务B的修改结果，导致事务B违反ACID。 这也正是所谓的 `第一类更新丢失` 的情况。
  - 也正是因为InnoDB使用的MVCC中结合了排他锁, 不是纯的MVCC, 所以第一类更新丢失是不会出现了, 一般说更新丢失都是指第二类丢失更新。

  参考：[多版本并发控制](https://segmentfault.com/a/1190000012650596)

## 字符集及校对规则

​		字符集指的是⼀种从⼆进制编码到某类字符符号的映射。校对规则则是指某种字符集下的排序规则。 MySQL中每⼀种字符集都会对应⼀系列的校对规则。

​		MySQL采⽤的是类似继承的⽅式指定字符集的默认值，每个数据库以及每张数据表都有⾃⼰的默认值， 他们逐层继承。⽐如：某个库中所有表的默认字符集将是该数据库所指定的字符集（这些表在没有指定 字符集的情况下，才会采⽤默认字符集）

​		详细内容可以参考：[MySQL字符集及校对规则的理解](https://www.cnblogs.com/geaozhang/p/6724393.html)

## 索引

​		MySQL索引使⽤的数据结构主要有BTree索引 和 哈希索引 。对于哈希索引来说，底层的数据结构就是 哈希表，因此在绝⼤多数需求为单条记录查询的时候，可以选择哈希索引，查询性能最快；其余⼤部分 场景，建议选择BTree索引。 MySQL的BTree索引使⽤的是B树中的B+Tree，但对于主要的两种存储引擎的实现⽅式是不同的。

- MyISAM: B+Tree叶节点的data域存放的是数据记录的地址。在索引检索的时候，⾸先按照B+Tree 搜索算法搜索索引，如果指定的Key存在，则取出其 data 域的值，然后以 data 域的值为地址 读取相应的数据记录。这被称为“**⾮聚簇索引**”。
- InnoDB: 其数据⽂件本身就是索引⽂件。相⽐MyISAM，索引⽂件和数据⽂件是分离的，其表数据 ⽂件本身就是按B+Tree组织的⼀个索引结构，树的叶节点data域保存了完整的数据记录。这个索 引的key是数据表的主键，因此InnoDB表数据⽂件本身就是主索引。这被称为“聚簇索引（或聚集 索引）”。⽽其余的索引都作为辅助索引，辅助助索引的data域存储相应记录主键的值⽽不是地 址，这也是和MyISAM不同的地⽅。在根据主索引搜索时，直接找到key所在的节点即可取出数 据；在根据辅助索引查找时，则需要先取出主键的值，再⾛⼀遍主索引。 因此，在设计表的时 候，不建议使⽤过⻓的字段作为主键，也不建议使⽤⾮单调的字段作为主键，这样会造成主索引 频繁分裂。

## 查询缓存

> 执⾏查询语句的时候，会先查询缓存。不过，MySQL 8.0 版本后移除，因为这个功能不太实⽤

​		my.cnf加⼊以下配置，重启MySQL开启查询缓存

```
query_cache_type=1
query_cache_size=600000
```

​		MySQL执⾏以下命令也可以开启查询缓存

```
set global query_cache_type=1;
set global query_cache_size=600000;
```

如上，开启查询缓存后在同样的查询条件以及数据情况下，会直接在缓存中返回结果。这⾥的查询条件 包括查询本身、当前要查询的数据库、客户端协议版本号等⼀些可能影响结果的信息。因此任何两个查 询在任何字符上的不同都会导致缓存不命中。此外，如果查询中包含任何⽤户⾃定义函数、存储函数、 ⽤户变量、临时表、MySQL库中的系统表，其查询结果也不会被缓存。 缓存建⽴之后，MySQL的查询缓存系统会跟踪查询中涉及的每张表，如果这些表（数据或结构）发⽣变 化，那么和这张表相关的所有缓存数据都将失效。 缓存虽然能够提升数据库的查询性能，但是缓存同时也带来了额外的开销，每次查询后都要做⼀次缓存 操作，失效后还要销毁。 因此，开启缓存查询要谨慎，尤其对于写密集的应⽤来说更是如此。如果开 启，要注意合理控制缓存空间⼤⼩，⼀般来说其⼤⼩设置为⼏⼗MB⽐᫾合适。此外，还可以通过 sql_cache和sql_no_cache来控制某个查询语句是否需要缓存：

```
select sql_no_cache count(*) from usr;
```

## 并发事务带来的问题

在典型的应⽤程序中，多个事务并发运⾏，经常会操作相同的数据来完成各⾃的任务（多个⽤户对同⼀ 数据进⾏操作）。并发虽然是必须的，但可能会导致以下的问题。

- **脏读（Dirty read）**: 当⼀个事务正在访问数据并且对数据进⾏了修改，⽽这种修改还没有提交 到数据库中，这时另外⼀个事务也访问了这个数据，然后使⽤了这个数据。因为这个数据是还没 有提交的数据，那么另外⼀个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是 不正确的。
- **丢失修改（Lost to modify）**: 指在⼀个事务读取⼀个数据时，另外⼀个事务也访问了该数据， 那么在第⼀个事务中修改了这个数据后，第⼆个事务也修改了这个数据。这样第⼀个事务内的修 改结果就被丢失，因此称为丢失修改。 例如：事务1读取某表中的数据A=20，事务2也读取 A=20，事务1修改A=A-1，事务2也修改A=A-1，最终结果A=19，事务1的修改被丢失。
- **不可重复读（Unrepeatableread）**: 指在⼀个事务内多次读同⼀数据。在这个事务还没有结束 时，另⼀个事务也访问该数据。那么，在第⼀个事务中的两次读数据之间，由于第⼆个事务的修 改导致第⼀个事务两次读取的数据可能不太⼀样。这就发⽣了在⼀个事务内两次读到的数据是不 ⼀样的情况，因此称为不可重复读。
- **幻读（Phantom read）**: 幻读与不可重复读类似。它发⽣在⼀个事务（T1）读取了⼏⾏数据，接 着另⼀个并发事务（T2）插⼊了⼀些数据时。在随后的查询中，第⼀个事务（T1）就会发现多了 ⼀些原本不存在的记录，就好像发⽣了幻觉⼀样，所以称为幻读。

## 锁机制与InnoDB锁算法

MyISAM和InnoDB存储引擎使⽤的锁：

- MyISAM采⽤表级锁(table-level locking)。
- InnoDB⽀持⾏级锁(row-level locking)和表级锁,默认为⾏级锁

表级锁和⾏级锁对⽐：

- 表级锁： MySQL中锁定 粒度最⼤ 的⼀种锁，对当前操作的整张表加锁，实现简单，资源消耗也 ⽐᫾少，加锁快，不会出现死锁。其锁定粒度最⼤，触发锁冲突的概率最⾼，并发度最低， MyISAM和 InnoDB引擎都⽀持表级锁。
- ⾏级锁： MySQL中锁定 粒度最⼩ 的⼀种锁，只针对当前操作的⾏进⾏加锁。 ⾏级锁能⼤⼤减 少数据库操作的冲突。其加锁粒度最⼩，并发度⾼，但加锁的开销也最⼤，加锁慢，会出现死 锁。

参考：[MySQL锁机制](https://blog.csdn.net/qq_34337272/article/details/80611486)

InnoDB存储引擎的锁的算法有三种：

- Record lock：单个⾏记录上的锁
- Gap lock：间隙锁，锁定⼀个范围，不包括记录本身
- Next-key lock：record+gap 锁定⼀个范围，包含记录本身

相关知识点：

- innodb对于⾏的查询使⽤next-key lock
- Next-locking keying为了解决Phantom Problem幻读问题
- 当查询的索引含有唯⼀属性时，将next-key lock降级为record key
- Gap锁设计的⽬的是为了阻⽌多个事务将记录插⼊到同⼀范围内，⽽这会导致幻读问题的产⽣
- 有两种⽅式显式关闭gap锁：（除了外键约束和唯⼀性检查外，其余情况仅使⽤record lock） A. 将事务隔离级别设置为RC B. 将参数innodb_locks_unsafe_for_binlog设置为1

# 数据库设计规范

## 字段设计规范

**优先选择符合存储需要的最小的数据类型**

列的字段越大，建立索引时所需要的空间也就越大，这样一页中所能存储的索引节点的数量也就越少也越少，在遍历时所需要的 IO 次数也就越多，索引的性能也就越差。如将字符串转换成数字类型存储（将 IP 地址转换成整形数据、对于非负型的数据 (如自增 ID,整型 IP) 来说,要优先使用无符号整型来存储等）。

**避免使用 TEXT,BLOB 数据类型，最常见的 TEXT 类型可以存储 64k 的数据**

建议把 BLOB 或是 TEXT 列分离到单独的扩展表中，MySQL 内存临时表不支持 TEXT、BLOB 这样的大数据类型，如果查询中包含这样的数据，在排序等操作时，就不能使用内存临时表，必须使用磁盘临时表进行。而且对于这种数据，MySQL 还是要进行二次查询，会使 sql 性能变得很差，但是不是说一定不能使用这样的数据类型。

如果一定要使用，建议把 BLOB 或是 TEXT 列分离到单独的扩展表中，查询时一定不要使用 select * 而只需要取出必要的列，不需要 TEXT 列的数据时不要对该列进行查询。

TEXT 或 BLOB 类型只能使用前缀索引，因为MySQL[1] 对索引字段长度是有限制的，所以 TEXT 类型只能使用前缀索引，并且 TEXT 列上是不能有默认值的。

**避免使用 ENUM 类型**

修改 ENUM 值需要使用 ALTER 语句；ENUM 类型的 ORDER BY 操作效率低，需要额外操作；禁止使用数值作为 ENUM 的枚举值。

**尽可能把所有列定义为 NOT NULL**

索引 NULL 列需要额外的空间来保存，所以要占用更多的空间，进行比较和计算时要对 NULL 值做特别的处理。

**使用 TIMESTAMP(4 个字节) 或 DATETIME 类型 (8 个字节) 存储时间**

TIMESTAMP 存储的时间范围 1970-01-01 00:00:01 ~ 2038-01-19-03:14:07，TIMESTAMP 占用 4 字节和 INT 相同，但比 INT 可读性高，超出 TIMESTAMP 取值范围的使用 DATETIME 类型存储；经常会有人用字符串存储日期型的数据（不正确的做法），这样无法用日期函数进行计算和比较，而且用字符串存储日期要占用更多的空间。

**同财务相关的金额类数据必须使用 decimal 类型**

Decimal 类型为精准浮点数，在计算时不会丢失精度，而float,double为非精准浮点；占用空间由定义的宽度决定，每 4 个字节可以存储 9 位数字，并且小数点要占用一个字节；可用于存储比 bigint 更大的整型数据

## 索引设计规范

**限制每张表上的索引数量,建议单张表索引不超过 5 个**

**禁止给表中的每一列都建立单独的索引**

**每个 Innodb 表必须有个主键**

Innodb 是一种索引组织表：数据的存储的逻辑顺序和索引的顺序是相同的；每个表都可以有多个索引，但是表的存储顺序只能有一种；Innodb 是按照主键索引的顺序来组织表的；不要使用更新频繁的列作为主键，不适用多列主键（相当于联合索引）；不要使用 UUID,MD5,HASH,字符串列作为主键（无法保证数据的顺序增长）；主键建议使用自增 ID 值

如何选择索引列的顺序

避免建立冗余索引和重复索引（增加了查询优化器生成执行计划的时间）

## SQL设计规范

1. 建议使用预编译语句进行数据库操作

2. 避免数据类型的隐式转换

3. 充分利用表上已经存在的索引

4. 数据库设计时，应该要对以后扩展进行考虑

5. 序连接不同的数据库使用不同的账号，进制跨库查询

6. 禁止使用 SELECT * 必须使用 SELECT <字段列表> 查询

7. 禁止使用不含字段列表的 INSERT 语句

8. 避免使用子查询，可以把子查询优化为 join 操作

9. 避免使用 JOIN 关联太多的表

10. 减少同数据库的交互次数

11. 对应同一列进行 or 判断时，使用 in 代替 or

12. 禁止使用 order by rand() 进行随机排序

13. WHERE 从句中禁止对列进行函数转换和计算

14. 在明显不会有重复值时使用 UNION ALL 而不是 UNION

15. 拆分复杂的大 SQL 为多个小 SQL

16. 如果知道查询结果只有一条或者只要最大/最小一条记录，建议用limit 1

17. 优化limit分页

18. 应尽量避免在 where 子句中对字段进行表达式操作，这将导致系统放弃使用索引而进行全表扫

19. Inner join 、left join、right join，优先使用Inner join，如果是left join，左边表结果尽量小

20. 如果插入数据过多，考虑批量插入

21. 在适当的时候，使用覆盖索引

22. where子句中考虑使用默认值代替null

23. 为了提高group by 语句的效率，可以在执行到该语句前，把不需要的记录过滤掉

24. 如果字段类型是字符串，where时一定用引号括起来，否则索引失效

## 表设计规范

临时库表必须以 tmp_为前缀并以日期为后缀，备份表必须以 bak_为前缀并以日期 (时间戳) 为后缀。

尽量控制单表数据量的大小,建议控制在 500 万以内，500 万并不是 MySQL 数据库的限制，过大会造成修改表结构，备份，恢复都会有很大的问题；可以用历史数据归档（应用于日志数据），分库分表（应用于业务数据）等手段来控制数据量大小。

## 库设计规范

超 100 万行的批量写 (UPDATE,DELETE,INSERT) 操作,要分批多次进行操作。

对于大表使用 pt-online-schema-change 修改表结构。

禁止为程序使用的账号赋予 super 权限。

对于程序连接数据库账号,遵循权限最小原则。

# 单表优化

不要上来就考虑分库分表，这样会带来逻辑、运维、部署的各种问题；一般来说，以整型值为主的表在千万级以下，字符串为主的表在五百万以下是没有问题的；同时MySQL单表的性能仍然可以进行优化，甚至能正常支撑千万级以上的数据量

**字段优化**

- 尽量使用TINYINT、SMALLINT、MEDIUM_INT作为整数类型而非INT，如果非负则加上UNSIGNED
- VARCHAR的长度只分配真正需要的空间
- 使用枚举或整数代替字符串类型
- 尽量使用TIMESTAMP而非DATETIME
- 单表不要有太多字段，建议在20以内
- 避免使用NULL字段，很难查询优化且占用额外索引空间
- 用整型来存IP
- 索引并不是越多越好，要根据查询有针对性的创建，考虑在WHERE和ORDER BY命令上涉及的列建立索引，可根据EXPLAIN来查看是否用了索引还是全表扫描
- 应尽量避免在WHERE子句中对字段进行NULL值判断，否则将导致引擎放弃使用索引而进行全表扫描
- 值分布很稀少的字段不适合建索引，例如"性别"这种只有两三个值的字段
- 字符字段只建前缀索引
- 字符字段最好不要做主键
- 不用外键，由程序保证约束
- 尽量不用UNIQUE，由程序保证约束
- 使用多列索引时主意顺序和查询条件保持一致，同时删除不必要的单列索引

**查询SQL**

- 可通过开启慢查询日志来找出较慢的SQL
- 不做列运算：SELECT id WHERE age + 1 = 10，任何对列的操作都将导致表扫描，它包括数据库教程函数、计算表达式等等，查询时要尽可能将操作移至等号右边
- sql语句尽可能简单：一条sql只能在一个cpu运算；大语句拆小语句，减少锁时间；一条大sql可以堵死整个库
- 不用SELECT *
- OR改写成IN：OR的效率是n级别，IN的效率是log(n)级别，in的个数建议控制在200以内
- 不用函数和触发器，在应用程序实现
- 避免%xxx式查询
- 少用JOIN
- 使用同类型进行比较，比如用'123'和'123'比，123和123比
- 尽量避免在WHERE子句中使用!=或<>操作符，否则将引擎放弃使用索引而进行全表扫描
- 对于连续数值，使用BETWEEN不用IN：SELECT id FROM t WHERE num BETWEEN 1 AND 5
- 列表数据不要拿全表，要使用LIMIT来分页，每页数量也不要太大

# 分库分表

## 为什么要进行分库分表？

- 考察点1：为什么要分库分表（设计高并发系统的时候，数据库层面如何设计？）

- 考察点2：用过哪些分库分表中间件？他们的优势和劣势是什么？

- 考察点3：具体如何对数据库进行垂直拆分或水平拆分的？

​		分库分表一定是为了支撑高并发、数据量大两个问题。具体来说，可能分表不分库，也可能分库不分表。

- **分表**：单表数据量过大，会极大影响你的sql执行性能（一般单表几百万数据）

- **分库**：一个库最多支撑并发2000,，就需要扩容了，一个健康的单库并发最好保持在每秒1000左右

​        **常见分库分表中间件：Sharding-jdbc、Mycat**

​		sharding-jdbc：当当开源，Client层方案，支持分库分表、读写分离、分布式id生成、柔性事务（最大努力送达型事务、TCC事务）。优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能相对较高；缺点是升级时需要各个系统都重新升级版本再发布，各个系统都耦合了sharding-jdbc的依赖。

​		Mycat：基于Cobar改造，proxy层方案，功能完善。优点是各个项目之间是透明的，不需要管Mycat的升级版本等问题；缺点是需要部署，自己运维一套中间件，成本高。

​		水平拆分：将单表的数据分担到多个库的多个表里，表的结构都一样，所有表的数据加起来才是全部数据。（作用就是用多个库来扛更高的并发，以及用多个库的存储容量来进行扩容）

​		![database-split-horizon](https://doocs.github.io/advanced-java/docs/high-concurrency/images/database-split-horizon.png)

​		垂直拆分：将单表的很多字段进行拆分成多个表，或者是多个库，每个表的结构不同（几张不同的关联表）；一般会将较少访问频率高的字段放入一个表，将较多的访问频率较少的字段放入另外一个表

![database-split-vertically](https://doocs.github.io/advanced-java/docs/high-concurrency/images/database-split-vertically.png)

​		上述中间件都支持分库分表，中间件可以根据你指定的某个字段值，比如说userid，自动路由到对应的库，然后再自动路由到对应的表里去。

​		分库分表的方式：

1. range：每个库一段连续的数据，比如时间范围。优点是：扩容简单，如每个月一个库；缺点是这种方法容易产生热点问题，即流量都打在最新数据上。
2. hash：按照某字段hash一下均匀分散，较为常用；优点是每个库的数据量和请求压力平均分布，缺点是扩容麻烦，在数据迁移时，之前的数据需要重新计算hash值并重新分配到不同的库或表

## 分库分表如何平滑过渡？

- 考察点：即如何设计才能让系统从单库单表**动态切换**到分库分表上？

**分库分表的常见步骤**

- 选择一个数据库中间件，调研、学习、测试；
- 设计你的分库分表的一个方案，你要分成多少个库，每个库分成多少个表，比如 3 个库，每个库 4 个表；
- 基于选择好的数据库中间件，以及在测试环境建立好的分库分表的环境，然后测试一下能否正常进行分库分表的读写；
- 完成单库单表到分库分表的**迁移**，双写方案；
- 线上系统开始基于分库分表对外提供服务；

**停机迁移方案**

挂公告：0点~6点运维，无法访问；0点时，系统停掉，提前写好**导数的一次性工具**，此时跑起来，将单库单表的数据读出来并写入分库分表里；导数完毕后，修改数据库连接配置、代码、SQL等。（比较low的方案）

![database-shard-method-1](https://doocs.github.io/advanced-java/docs/high-concurrency/images/database-shard-method-1.png)

**双写迁移方案**

在线上系统，之前所有写库的地方，增删改操作，除了对老库增删改，都加上对新库的增删改，这就是所谓的**双写**，即同时写老库和新库。

系统部署后，新库数据肯定差很多，用上文说的导数工具，跑起来读老库数据写新库，写的时候根据gmt_modified这类字段判断这条数据最后修改的时间，除非是读出来的数据在新库里没有，或者是比新库的数据新才会写（即不允许老数据覆盖新数据）

导完一轮后，有可能数据还是不一致，需要程序自动做一轮校验，若有不一样的，从老库读数据再次写，反复循环，直到两个库所有表的数据一致为止。

![database-shard-method-2](https://doocs.github.io/advanced-java/docs/high-concurrency/images/database-shard-method-2.png)

## 如何设计可以动态的扩容方案？

- 考察点：在分库分表完成后，已经建立好的库和表支撑不住了，如何进行扩容？

**停机扩容（不推荐）**

步骤类似停机迁移，唯一不同是导数工具需要把现有库表的数据抽取慢慢倒入新的库表，但不推荐，一般来说，分库分表就是因为数据量过大；在单库单表到分库分表的时候，数据量可能不是很大，单表可能就两三千万，可以写个工具，多弄几台机器并行跑，1小时可能就完事了；倘若3个库+12张表，数据量达到亿级别，导数据就得几个小时，后续还得修改配置，重启系统，测试验证...

**优化方案**

可以一开始就32库+32表，即1024张表（无论并发支撑或数据量支撑都没问题），利用模32的方法进行路由

假设每个库正常承载写入并发量1000,32个库就是3.2w，如果每个库承载1.5k的写并发，即可以达到1.5*32=4.8w的写并发，再加一个MQ，削峰，每秒写入MQ8w条，每秒消费5w条；

对于数据量，每个表放500万，那么可以放50亿条数据

开始可能这个库是逻辑库，即一个MySQL服务器建了n个库，比如32，后面拆分就是在库和MySQL服务器之间做迁移，系统改一下配置；这样最多可以扩展到32个MySQL服务器，每个数据库服务器是一个库；若还不够，最多可以扩展到1024个服务器，每个数据库一张表；若需要减少库的数量，只要按倍数缩容就行了，修改一下路由规则

步骤：

1. 设定好几台数据库服务器，每台服务器上几个库，每个库多少个表，推荐是 32 库 * 32 表，对于大部分公司来说，可能几年都够了
2. 路由的规则，orderId 模 32 = 库，orderId / 32 模 32 = 表
3. 扩容的时候，申请增加更多的数据库服务器，装好 MySQL，呈倍数扩容，4 台服务器，扩到 8 台服务器，再到 16 台服务器
4. 由 DBA 负责将原先数据库服务器的库，迁移到新的数据库服务器上去，库迁移是有一些便捷的工具的
5. 我们这边就是修改一下配置，调整迁移的库所在数据库服务器的地址
6. 重新发布系统，上线，原先的路由规则变都不用变，直接可以基于 n 倍的数据库服务器的资源，继续进行线上系统的提供服务

## 分库分表之后，id主键如何处理？（分布式id）

- 考察点：分成多个表之后，每个表的id都是从1开始累加，这时需要一个全局唯一的id来支持

**数据库自增id**

系统每次得到一个id，往一个库的一个表里插入一条无含义的业务数据，然后获取数据库自增的这个id，拿到这个id后再到分库分表里进行写入。

好处是方便简单，缺点是**单库生成**自增id，高并发场景下不适用；改进：开一个服务，这个服务拿到当前最大id值，自己递增几个id，一次性返回一批id，然后再把最大id修改成递增几个id最大的一个值，但都是基于单库

适合场景：若是由于**并发不高、数据量过大**导致的分库分表扩容，可以采用这个方案

###### 		设置数据库sequence或者表自增字段步长

可以通过设置数据库 sequence 或者表的自增字段步长来进行水平伸缩。

比如说，现在有 8 个服务节点，每个服务节点使用一个 sequence 功能来产生 ID，每个 sequence 的起始 ID 不同，并且依次递增，步长都是 8。

![database-id-sequence-step](https://doocs.github.io/advanced-java/docs/high-concurrency/images/database-id-sequence-step.png)

适合场景：在用户防止产生id重复时，可以使用；但服务节点固定、步长固定，若需要增加节点，就不好操作了

**UUID**

`UUID.randomUUID().toString().replace("-", "") -> sfsdf23423rr234sfdaf`

上述两种方式都是基于数据库，这种就是本地生成；缺点是UUID过长，占用空间大，且**作为主键性能太差**；更重要的是，UUID不具有有序性，会导致 B+ 树索引在写的时候有过多的随机写操作（连续的 ID 可以产生部分顺序写），还有，由于在写的时候不能产生有顺序的 append 操作，而需要进行 insert 操作，将会读取整个 B+ 树节点到内存，在插入这条记录后会将整个节点写回磁盘，这种操作在记录占用空间比较大的情况下，性能下降明显。

适合场景：随机生成文件名、编号等，主键不能用UUID

**获取系统当前时间**

在高并发条件下，比如一秒并发几千，会有重复情况，不用考虑

适合场景：可以将当前时间+业务字段组合作为id

**snowflake算法**

twitter开源的分布式id生成算法，采用Scala语言实现，是把一个 64 位的 long 型的 id，1 个 bit 是不用的，用其中的 41 bits 作为毫秒数，用 10 bits 作为工作机器 id，12 bits 作为序列号

```
0 | 0001100 10100010 10111110 10001001 01011100 00 | 10001 | 1 1001 | 0000 00000000
```

- 1 bit：不用，为啥呢？因为二进制里第一个 bit 为如果是 1，那么都是负数，但是我们生成的 id 都是正数，所以第一个 bit 统一都是 0。
- 41 bits：表示的是时间戳，单位是毫秒。41 bits 可以表示的数字多达 `2^41 - 1` ，也就是可以标识 `2^41 - 1` 个毫秒值，换算成年就是表示69年的时间。
- 10 bits：记录工作机器 id，代表的是这个服务最多可以部署在 2^10 台机器上，也就是 1024 台机器。但是 10 bits 里 5 个 bits 代表机房 id，5 个 bits 代表机器 id。意思就是最多代表 `2^5` 个机房（32 个机房），每个机房里可以代表 `2^5` 个机器（32台机器）。
- 12 bits：这个是用来记录同一个毫秒内产生的不同 id，12 bits 可以代表的最大正整数是 `2^12 - 1 = 4096` ，也就是说可以用这个 12 bits 代表的数字来区分**同一个毫秒内**的 4096 个不同的 id。

# 读写分离

考察点：高并发肯定需要做读写分离，而且大部分场景都是读多写少，即写一个主库，挂多个从库，从多个从库来读，那么如何实现MySQL的读写分离？MySQL主从复制的原理是什么？如何解决MySQL主从同步的延时问题？

**如何实现MySQL的读写分离？**

即基于主从复制架构，即一个主库，挂多个从库，主库用来写，然后主库会将数据同步到从库

###### 		MySQL主从复制原理是什么？

主库将变更写入binlog日志，然后从库连接到主库之后，从库有一个IO线程，将主库的binlog日志拷贝到自己本地，写入一个relay中继日志中，接着从库中有一个SQL线程会从中继日志中读取binlog，然后执行binlog日志中的内容，也就是在自己本地再次执行一遍SQL，这样即可以保证自己跟主库的数据是一样的

![mysql-master-slave](https://doocs.github.io/advanced-java/docs/high-concurrency/images/mysql-master-slave.png)

**主从同步延时问题**

主库上写入binlog日志是并行的，但从库上同步数据是串行化的，在高并发场景下，从库的数据一定会比主库慢一些，**有延时性**，可能经常刚写入主库的数据读不到，要等几十毫秒等才能读到

**从库数据丢失问题**

如果主库突然宕机，数据还没同步到从库，有些数据在从库上就丢失了

**半同步复制**

解决从库数据丢失问题。半同步复制也叫semi-sync复制，指的是主库写入binlog日志后，就会**强制**立即将数据同步到从库，从库将日志写入自己本地的relay log后，会返回一个ack给主库，主库接收到至少一个从库的ack之后才会确认写操作已完成

**并行复制**

解决主从同步延时问题。指的是从库开启多个线程，并行读取relay log中不同库的日志，然后并行重放不同库的日志，这是库级别的并行。

一般来说，如果主从延迟较为严重，有以下解决方案：

- 分库，将一个主库拆分为多个主库，每个主库的写并发就减少了几倍，此时主从延迟可以忽略不计。
- 打开 MySQL 支持的并行复制，多个库并行复制。如果说某个库的写入并发就是特别高，单库写并发达到了 2000/s，并行复制还是没意义。
- 重写代码，写代码的同学，要慎重，插入数据时立马查询可能查不到。
- 如果确实是存在必须先插入，立马要求就查询到，然后立马就要反过来执行一些操作，对这个查询**设置直连主库**。**不推荐**这种方法，你要是这么搞，读写分离的意义就丧失了。

# Q&A

**数据库的三范式是什么？什么是反模式？**

**MySQL 有哪些数据类型？**

**MySQL 中 varchar 与 char 的区别？varchar(50) 中的 50 代表的涵义？**

**int(11) 中的 11 代表什么涵义？**

**金额(金钱)相关的数据，选择什么数据类型？**

**一张表，里面有 ID 自增主键，当 insert 了 17 条记录之后，删除了第 15,16,17 条记录，再把 MySQL 重启，再 insert 一条记录，这条记录的 ID 是 18 还是 15？**

**表中有大字段 X(例如：text 类型)，且字段 X 不会经常更新，以读为为主，请问您是选择拆成子表，还是继续放一起?写出您这样选择的理由**

**MySQL 有哪些存储引擎？**

**如何选择合适的存储引擎？**

**请说明 InnoDB 和 MyISAM 的区别**

**请说说 InnoDB 的 4 大特性？**

**为什么 SELECT COUNT(\*) FROM table 在 InnoDB 比 MyISAM 慢？**

**什么是索引？索引的好处与坏处是什么**

**索引的使用场景？**

**索引的类型？**

**MySQL 索引的“创建”原则？**

**MySQL 索引的“使用”注意事项？**

**explain语句**

**MySQL 索引的原理？**

**MySQL 有哪些索引方法？**

**什么是 B-Tree 索引？**

说下mysql的优化方案
