数据结构与算法解决的是如何让代码运行的更快，如何更加节省存储空间

**如何分析、统计算法的执行效率和资源消耗**

**为什么需要复杂度分析？**

通过事后对算法的执行时间和占用内存进行统计、监控来得到算法执行的时间和内存大小，叫**事后统计法**，这种评估算法执行效率的方法是对的，但存在一些局限性

- 测试结果非常依赖测试环境（处理器的不同）
- 测试结果受数据规模的影响很大（例如小规模数据可能插入排序比快速排序还快，又或待排序数据的有序度也会影响执行时间）

所以，我们需要一个不用具体的测试数据来测试，就可以粗略地估计算法的执行效率的方法，即大O复杂度表示法

**大O复杂度表示法**

表示代码执行时间随数据规模增长的变化趋势，所以，也叫作**渐进时间复杂度**（asymptotic time complexity），简称**时间复杂度**。如T(n) = O(n)； T(n) = O(n2)。

**时间复杂度分析**：

1. 只关注循环执行次数最多的一段代码
2. 加法法则：总复杂度等于量级最大的那段代码的复杂度
3. 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积

![](F:\github\super-java\picture\设计模式之美-时间复杂度.jpg)

对于刚罗列的复杂度量级，我们可以粗略地分为两类，多项式量级和非多项式量级。其中，非多项式量级只有两个：O(2n) 和 O(n!)。**当数据规模 n 越来越大时，非多项式量级算法的执行时间会急剧增加，求解问题的执行时间会无限增长。**

**空间复杂度分析**：**渐进空间复杂度**（asymptotic space complexity），**表示算法的存储空间与数据规模之间的增长关系**，常见的空间复杂度就是 O(1)、O(n)、O(n2 )

**浅析最好、最坏、平均、均摊时间复杂度**

```
// n表示数组array的长度
int find(int[] array, int n, int x) { 
	int i = 0; 
	int pos = -1; 
	for (; i < n; ++i) { 
		if (array[i] == x) { 
			pos = i; 
			break;   //此处结束可以结束循环，节省时间
		} 
	} 
	return pos;
}
```

- 最好、最坏情况时间复杂度

最好情况就是在数组第一个元素就匹配到了，最坏即在数组最后一个元素才找到x

- 平均情况时间复杂度

要查找的变量 x 在数组中的位置，有 n+1 种情况：在数组的 0～n-1 位置中和不在数组中。我们把每种情况下，查找需要遍历的元素个数累加起来，然后再除以 n+1，就可以得到需要遍历的元素个数的平均值，即：

![平均时间复杂度](F:\github\super-java\picture\平均时间复杂度.jpg)

其实在0~n-1位置中和不在数组中的概率这样统计并不好，但可以认为其时间复杂度为O(n)

- 均摊时间复杂度

```
// array表示一个长度为n的数组 
// 代码中的array.length就等于n 
	int[] array = new int[n]; 
	int count = 0; 
	void insert(int val) { 
		if (count == array.length) { 
			int sum = 0; 
			for (int i = 0; i < array.length; ++i) { 
				sum = sum + array[i]; 
			} 
			array[0] = sum; 
			count = 1; 
		} 
		array[count] = val; 
		++count; 
	}
```

最好是直接插入，即O(1)，最坏情况是数组已满，需要求和清空数组，即O(n)

平均时间复杂度是1\*1/n+1+....+n\*1/n+1，即O(1)

每一次 O(n) 的插入操作，都会跟着 n-1 次 O(1) 的插入操作，所以把耗时多的那次操作均摊到接下来的 n-1 次耗时少的操作上，均摊下来，这一组连续的操作的均摊时间复杂度就是 O(1)。

**摊还分析法**：对一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，而且这些操作之间存在前后连贯的时序关系，这时看**是否能将较高时间复杂度那次操作的耗时，平摊到其他那些时间复杂度比较低的操作上**。而且，在能够应用均摊时间复杂度分析的场合，一般均摊时间复杂度就等于最好情况时间复杂度。