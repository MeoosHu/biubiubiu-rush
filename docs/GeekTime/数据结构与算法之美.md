### 为什么要学习数据结构和算法

编程能力强的体现之一是性能的好坏，而数据结构和算法能够帮你写出更优的代码。

算法其实是一种解决问题的思路和方法论。

> 很多大龄候选人，简历能写十几页，经历的项目有几十个，但是细看下来，每个项目都是重复地堆砌业务逻辑而已，完全没有难度递进，看不出有能力提升

数据结构与算法:

![](../../picture/basic_data_structures_and_algorithms.jpg)

值得攻克的数据结构与算法：

- 数据结构：数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie 树
- 算法：递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法

### 复杂度分析

#### 如何分析、统计算法的执行效率和资源消耗

通过事后对算法的执行时间和占用内存进行统计，这种评估算法执行效率的方法是对的，但存在一些局限性

- 测试结果非常依赖测试环境
- 测试结果受数据规模的影响很大

**大O复杂度表示法**：表示代码执行时间随数据规模增长的变化趋势，所以，也叫作**渐进时间复杂度**（asymptotic time complexity），简称**时间复杂度**。如T(n) = O(n)； T(n) = O(n2)。

**时间复杂度分析**：

1. 只关注循环执行次数最多的一段代码
2. 加法法则：总复杂度等于量级最大的那段代码的复杂度
3. 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积

![](../../picture/设计模式之美-时间复杂度.jpg)

**空间复杂度分析**：**渐进空间复杂度**（asymptotic space complexity），**表示算法的存储空间与数据规模之间的增长关系**，常见的空间复杂度就是 O(1)、O(n)、O(n2 )

#### 浅析最好、最坏、平均、均摊时间复杂度

- 最好情况时间复杂度
- 最坏情况时间复杂度
- 平均情况时间复杂度
- 均摊时间复杂度

### 常见数据结构

#### 数组

**为什么数组要从 0 开始编号，而不是从 1 开始呢？**

```
a[k]_address = base_address + k * type_size
```

”下标”最确切的定义应该是“偏移（offset）”

**如何实现随机访问？**

> 数组（Array）是一种***线性表***数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。

特点：

- **线性表**：每个线性表上的数据最多只有前和后两个方向，例如数组、链表、队列、栈等，与之相对应的则是非线性表（二叉树、堆、图等）
- **连续的内存空间和相同类型的数据**

数组支持随机访问，**根据下标随机访问**的时间复杂度为 O(1)。

**低效的插入和删除**

优化：

1. 插入时，可以将某一位置的元素移至末尾，再添加元素到指定位置（快排）
2. 删除时，可以将多个位置的元素先标记，最终进行一次删除操作（JVM 标记清除垃圾回收算法）

**容器能否完全替代数组？**

在Java中，ArrayList 最大的优势就是**可以将很多数组操作的细节封装起来**，并且还**支持动态扩容**

数组的使用场景：

1. Java ArrayList 无法存储基本类型，比如 int、long，需要封装为 Integer、Long 类，而 Autoboxing、Unboxing 则有一定的性能消耗，所以如果特别关注性能，或者希望使用基本类型，就可以选用数组
2. 如果数据大小事先已知，并且对数据的操作非常简单，用不到 ArrayList 提供的大部分方法，也可以直接使用数组

#### 链表

**如何实现LRU缓存淘汰算法？**

缓存的大小有限，当缓存被用满时，哪些数据应该被清理出去，哪些数据应该被保留？这就需要缓存淘汰策略来决定。常见的策略有三种：先进先出策略 FIFO（First In，First Out）、最少使用策略 LFU（Least Frequently Used）、最近最少使用策略 LRU（Least Recently Used）

解决方法：

我们维护一个有序单链表，越靠近链表尾部的结点是越早之前访问的。当有一个新的数据被访问时，我们从链表头开始顺序遍历链表。

1. 如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，然后再插入到链表的头部。

2. 如果此数据没有在缓存链表中，又可以分为两种情况：

   - 如果此时缓存未满，则将此结点直接插入到链表的头部；
   - 如果此时缓存已满，则链表尾结点删除，将新的数据结点插入链表的头部。

   **优化方案**：引入散列表，记录每个数据的位置，将缓存访问的时间复杂度降到 O(1)

**底层存储结构**

链表是由一个个独立的内存块组成的，链表可分为单链表、循环链表、双向链表

1. 单链表：插入和删除的时间复杂度是O(1)，随机访问的时间复杂度为O(n)
2. 循环链表：尾结点指向头结点。优点是当要处理的数据具有环型结构特点时，就特别适合采用循环链表，比如著名的约瑟夫问题
3. 双向链表：不仅有后继指针next，还有前驱指针prev。双向链表可以支持 O(1) 时间复杂度的情况下找到**前驱结点**，对于有序链表的查找效率也较高一些。应用：LinkedHashMap，思想：空间换时间

**链表VS数组**

数组的优势在于使用的是连续的存储空间，可以借助CPU的缓存机制，随机访问效率高；缺点是大小固定，若数组过大，可能没有连续的内存空间分配，若数组过小，则可能出现空间不够用，此时进行扩容，原数组的拷贝非常耗时。而链表本身没有大小限制，天然支持动态扩容。

**写链表代码技巧**

- 理解指针或引用的含义

- 警惕指针丢失和内存泄漏

- 利用哨兵简化实现难度

  针对链表的插入、删除操作，需要对插入第一个结点和删除最后一个结点的情况进行特殊处理

  引入哨兵结点，在任何时候，不管链表是不是空，head 指针都会一直指向这个哨兵结点。我们也把这种有哨兵结点的链表叫**带头链表**。相反，没有哨兵结点的链表就叫作**不带头链表**

- 重点留意边界条件处理

- 举例画图，辅助思考

- 多写多练，没有捷径

  - 单链表反转
  - 链表中环的检测
  - 两个有序的链表合并
  - 删除链表倒数第 n 个结点
  - 求链表的中间结点

#### 栈

**如何实现浏览器的前进和后退功能？**

利用两个栈实现，一个栈存储浏览过的页面，另一个存储返回后弹出的数据

**如何理解"栈"?**

后进者先出，先进者后出，就是典型的"栈"结构。

从栈的操作特性上来看，**栈是一种“操作受限”的线性表**，只允许在一端插入和删除数据

当某个数据集合只涉及在一端插入和删除数据，并且满足后进先出、先进后出的特性，我们就应该首选“栈”这种数据结构

**如何实现一个“栈”？**

栈主要包括入栈、出栈两个操作，用数组实现的栈叫**顺序栈**，用链表实现的栈叫**链式栈**

入栈和出栈都只涉及栈顶数据的操作，故栈的时间复杂度和空间复杂度都是O(1)

**支持动态扩容的顺序栈**

基于数组的栈是固定大小的，而基于链表的栈需存储指针，消耗内存

支持动态扩容后，出栈操作时间复杂度仍为O(1)，而入栈涉及扩容，将耗时多的入栈操作的时间均摊到其他入栈操作上，时间复杂度也接近O(1)

**栈的应用场景**

- 函数调用栈
- 表达式求值
- 括号匹配

**JVM中的"堆栈"和数据结构中的"栈"是一回事吗？**

#### 队列

**队列在线程池等有限资源池中的应用**

CPU 资源是有限的，任务的处理速度与线程个数并不是线性正相关。相反，过多的线程反而会导致 CPU 频繁切换，处理性能下降。所以，线程池的大小一般都是综合考虑要处理任务的特点和硬件环境，来事先设置的

当我们向固定大小的线程池中请求一个线程时，如果线程池中没有空闲资源了，这个时候线程池如何处理这个请求？是拒绝请求还是排队请求？各种处理策略又是怎么实现的呢？

一般有两种处理策略。第一种是非阻塞的处理方式，直接拒绝任务请求；另一种是阻塞的处理方式，将请求排队，等到有空闲线程时，取出排队的请求继续处理

基于链表实现的无界队列可能会导致过多的请求排队等待，不适合对响应时间比较敏感的系统；基于数组实现的有界队列，队列太大导致等待的请求太多，队列太小会导致无法充分利用系统资源、发挥最大性能

实际上，对于大部分资源有限的场景，当没有空闲资源时，基本上都可以通过“队列”这种数据结构来实现请求排队

**如何理解"队列"？**

**先进者先出**，队列也只支持两个操作，入队enqueue()：放一个数据到队列尾部；出队dequeue()：从队列头部取一个元素

队列也是一种**操作受限的线性表数据结构**

**顺序队列和链式队列**

用数组实现的队列叫作**顺序队列**，用链表实现的队列叫作**链式队列**

**循环队列**

队列为空的判断条件是 head == tail，队满时，**(tail+1)%n=head**

**阻塞队列和并发队列**

**阻塞队列**其实就是在队列基础上增加了阻塞操作。简单来说，就是在队列为空的时候，从队头取数据会被阻塞。因为此时还没有数据可取，直到队列中有了数据才能返回；如果队列已经满了，那么插入数据的操作就会被阻塞，直到队列中有空闲位置后再插入数据，然后再返回

线程安全的队列我们叫作**并发队列**。最简单直接的实现方式是直接在 enqueue()、dequeue() 方法上加锁，但是锁粒度大并发度会比较低，同一时刻仅允许一个存或者取操作。实际上，基于数组的循环队列，利用 CAS 原子操作，可以实现非常高效的并发队列。这也是循环队列比链式队列应用更加广泛的原因

#### 递归

**递归需要满足的三个条件**

1. 一个问题的解可以分解为几个子问题的解
2. 这个问题与分解之后的子问题，除了数据规模不同，求解思路完全一样
3. 存在递归终止条件

编写递归代码的关键是，只要遇到递归，我们就把它抽象成一个递推公式，不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤

**递归代码要警惕堆栈溢出**

如果递归求解的数据规模很大，调用层次很深，一直压入栈，就会有堆栈溢出的风险；可以通过在代码中限制递归调用的最大深度的方式来解决这个问题，但这种方法并不是很实用

**递归代码要警惕重复计算**

想要计算 f(5)，需要先计算 f(4) 和 f(3)，而计算 f(4) 还需要计算 f(3)，因此，f(3) 就被计算了很多次，这就是重复计算问题

**怎么将递归代码改写为非递归代码？**

改为这种**迭代循环**的非递归写法

### 排序算法

**如何分析一个“排序算法”？**

- 排序算法的执行效率

  - 最好情况、最坏情况、平均情况时间复杂度
  - 时间复杂度的系数、常数 、低阶
  - 比较次数和交换（或移动）次数

- 排序算法的内存消耗

  算法的内存消耗可以通过空间复杂度来衡量，不过，针对排序算法的空间复杂度，我们还引入了一个新的概念，**原地排序**，特指**空间复杂度**是 O(1) 的排序算法

- 排序算法的稳定性

  要排序的往往不是单纯的整数，而是一组对象，我们需要按照对象的某个 key 来排序；经过某种排序算法排序之后，如果两个对象的前后顺序没有改变，那我们就把这种排序算法叫作**稳定的排序算法**；如果前后顺序发生变化，那对应的排序算法就叫作**不稳定的排序算法**

#### 冒泡排序

> **有序度**：数组中具有有序关系的元素对的个数，如下
>
> ```
> 有序元素对：a[i] <= a[j], 如果 i < j。
> ```
>
> **满有序度**：对于一个完全有序的数组，比如 1，2，3，4，5，6，有序度就是**n\*(n-1)/2**，也就是 15，即满有序度
>
> 逆序度正好与有序度相反，**逆序度 = 满有序度 - 有序度**

冒泡排序是原地排序算法，也是稳定的，最好情况时间复杂度是 O(n)，最坏情况时间复杂度为 O(n2)

对于包含 n 个数据的数组进行冒泡排序，平均交换次数是多少呢？最坏情况下，初始状态的有序度是 0，所以要进行 n*(n-1)/2 次交换。最好情况下，初始状态的有序度是 n*(n-1)/2，就不需要进行交换。我们可以取个中间值 n*(n-1)/4，来表示初始有序度既不是很高也不是很低的平均情况

平均情况下，需要 n*(n-1)/4 次交换操作，比较操作肯定要比交换操作多，而复杂度的上限是 O(n2)，所以平均情况下的时间复杂度就是 O(n2)

#### 插入排序

插入排序是原地排序算法,也是稳定的，最好是时间复杂度为 O(n)，注意，这里是**从尾到头遍历已经有序的数据**，最坏情况时间复杂度为 O(n2)，平均时间复杂度为 O(n2)

**为何插入排序比冒泡排序更受欢迎？**

我们把执行一个赋值语句的时间粗略地计为单位时间（unit_time），然后分别用冒泡排序和插入排序对同一个逆序度是 K 的数组进行排序。用冒泡排序，需要 K 次交换操作，每次需要 3 个赋值语句，所以交换操作总耗时就是 3*K 单位时间。而插入排序中数据移动操作只需要 K 个单位时间

#### 选择排序

排序空间复杂度为 O(1)，是一种原地排序算法，不稳定；最好情况时间复杂度、最坏情况和平均情况时间复杂度都为 O(n2)

#### 归并排序

归并排序不是原地排序算法，空间复杂度为O(n)；归并排序是一个稳定的排序算法；归并排序的执行效率与要排序的原始数组的有序程度无关，所以其时间复杂度是非常稳定的，不管是最好情况、最坏情况，还是平均情况，时间复杂度都是 O(nlogn)

#### 快速排序

快速排序是原地排序算法，不稳定，快排的最好时间复杂度是 O(nlogn)，最坏情况下时间复杂度是O(n2)，

T(n) 在大部分情况下的时间复杂度都可以做到 O(nlogn)，只有在极端情况下，才会退化到 O(n2)

#### 桶排序

时间复杂度是 O(n) ；如果要排序的数据有 n 个，我们把它们均匀地划分到 m 个桶内，每个桶里就有 k=n/m 个元素。每个桶内部使用快速排序，时间复杂度为 O(k * logk)。m 个桶排序的时间复杂度就是 O(m * k * logk)，因为 k=n/m，所以整个桶排序的时间复杂度就是 O(n*log(n/m))。当桶的个数 m 接近数据个数 n 时，log(n/m) 就是一个非常小的常量，这个时候桶排序的时间复杂度接近 O(n)

桶排序对要排序数据的要求是非常苛刻的。首先，要排序的数据需要很容易就能划分成 m 个桶，并且，桶与桶之间有着天然的大小顺序。这样每个桶内的数据都排序完之后，桶与桶之间的数据不需要再进行排序。

其次，数据在各个桶之间的分布是比较均匀的。如果数据经过桶的划分之后，有些桶里的数据非常多，有些非常少，很不平均，那桶内数据排序的时间复杂度就不是常量级了。在极端情况下，如果数据都被划分到一个桶里，那就退化为 O(nlogn) 的排序算法了

**桶排序比较适合用在外部排序中**。所谓的外部排序就是数据存储在外部磁盘中，数据量比较大，内存有限，无法将数据全部加载到内存中。

#### 计数排序

**计数排序其实是桶排序的一种特殊情况**。当要排序的 n 个数据，所处的范围并不大的时候，比如最大值是 k，我们就可以把数据划分成 k 个桶。每个桶内的数据值都是相同的，省掉了桶内排序的时间。

**不过，为什么这个排序算法叫“计数”排序呢？“计数”的含义来自哪里呢？**

计数排序只能用在数据范围不大的场景，如果数据范围 k 比要排序的数据 n 大很多，就不适合用计数排序了。而且，计数排序只能给非负整数排序，如果要排序的数据是其他类型的，要将其在不改变相对大小的情况下，转化为非负整数

#### 基数排序

基数排序要求数据可以划分成高低位，位之间有递进关系。比较两个数，我们只需要比较高位，高位相同的再比较低位。而且每一位的数据范围不能太大，因为基数排序算法需要借助桶排序或者计数排序来完成每一个位的排序工作

**如何实现一个通用的、高性能的排序函数？**

- 如何选择合适的排序算法？

  线性排序算法的时间复杂度比较低，适用场景比较特殊。所以如果要写一个通用的排序函数，不能选择线性排序算法

  如果对小规模数据进行排序，可以选择时间复杂度是 O(n2) 的算法；如果对大规模数据进行排序，时间复杂度是 O(nlogn) 的算法更加高效。所以，为了兼顾任意规模数据的排序，一般都会首选时间复杂度是 O(nlogn) 的排序算法来实现排序函数。

  归并排序并不是原地排序算法，空间复杂度是 O(n);快速排序比较适合来实现排序函数

- 如何优化快速排序？

  如果数据原来就是有序的或者接近有序的，每次分区点都选择最后一个数据，那快速排序算法就会变得非常糟糕，时间复杂度就会退化为 O(n2)。实际上，**这种 O(n2) 时间复杂度出现的主要原因还是因为我们分区点选的不够合理**。

  最理想的分区点是：**被分区点分开的两个分区中，数据的数量差不多**。

  较常用、比较简单的分区算法有三数取中法，随机法

- 举例分析排序函数

  qsort() 并不仅仅用到了归并排序和快速排序，它还用到了插入排序。在小规模数据面前，**O(n2) 时间复杂度的算法并不一定比 O(nlogn) 的算法执行时间长**。对于小数据量的排序，我们选择比较简单、不需要递归的插入排序算法。

### 查找算法

#### 二分查找

问题：假设我们有 1000 万个整数数据，每个数据占 8 个字节，**如何设计数据结构和算法，快速判断某个整数是否出现在这 1000 万数据中？** 我们希望这个功能不要占用太多的内存空间，最多不要超过 100MB，你会怎么做呢？-----二分查找

二分查找针对的是一个**有序的数据集合**，查找思想有点类似分治思想。每次都通过跟区间的中间元素对比，将待查找的区间缩小为之前的一半，直到找到要查找的元素，或者区间被缩小为 0

**二分查找的递归与非递归实现**

**二分查找应用场景的局限性**

- 首先，二分查找依赖的是顺序表结构，简单点说就是数组。

- 其次，二分查找针对的是有序数据。

  二分查找只能用在插入、删除操作不频繁，一次排序多次查找的场景中。针对动态变化的数据集合，二分查找将不再适用

- 再次，数据量太小不适合二分查找。

  如果数据之间的比较操作非常耗时，不管数据量大小，我都推荐使用二分查找

- 最后，数据量太大也不适合二分查找。

  比如，我们有 1GB 大小的数据，如果希望用数组来存储，那就需要 1GB 的连续内存空间

**二分查找的变形问题**

1. 变体一：查找第一个值等于给定值的元素
2. 变体二：查找最后一个值等于给定值的元素
3. 变体三：查找第一个大于等于给定值的元素
4. 查找最后一个小于等于给定值的元素

#### 跳表

问题：**Redis 为什么会选择用跳表来实现有序集合呢？** 为什么不用红黑树呢？

**如何理解“跳表”？**

链表+多级索引的结构，就是跳表